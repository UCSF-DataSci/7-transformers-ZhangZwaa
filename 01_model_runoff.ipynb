{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05de9a44",
   "metadata": {},
   "source": [
    "# Part 1: Model Run-off (Systematic Model Selection)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this part, you'll implement a systematic approach to model selection for healthcare data. You'll compare multiple model architectures, evaluate their performance, and select the best model based on various metrics.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement a systematic model selection process\n",
    "- Compare multiple model architectures\n",
    "- Apply cross-validation techniques\n",
    "- Analyze performance trade-offs\n",
    "- Save model and metrics in the correct format\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c8e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.20.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.3.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (2.19.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.7.0)\n",
      "Requirement already satisfied: transformers>=4.18.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (4.51.3)\n",
      "Requirement already satisfied: requests>=2.27.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (2.32.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.5.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (0.31.2)\n",
      "Requirement already satisfied: accelerate>=0.12.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (1.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.2.0)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (0.21.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 22)) (3.6.0)\n",
      "Requirement already satisfied: regex>=2022.3.15 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 23)) (2024.11.6)\n",
      "Requirement already satisfied: plotly>=5.6.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 26)) (6.0.1)\n",
      "Requirement already satisfied: wandb>=0.12.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 29)) (0.19.11)\n",
      "Requirement already satisfied: pytest>=7.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 30)) (8.3.5)\n",
      "Requirement already satisfied: jupytext>=1.13.8 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: colorama in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tqdm>=4.62.0->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (5.29.4)\n",
      "Requirement already satisfied: setuptools in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (80.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: filelock in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (0.5.3)\n",
      "Requirement already satisfied: psutil in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from accelerate>=0.12.0->-r requirements.txt (line 17)) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (3.11.18)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from plotly>=5.6.0->-r requirements.txt (line 26)) (1.39.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (8.2.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (4.3.8)\n",
      "Requirement already satisfied: pydantic<3 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.11.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.28.0)\n",
      "Requirement already satisfied: setproctitle in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (1.3.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: iniconfig in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (1.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (0.4.2)\n",
      "Requirement already satisfied: nbformat in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (5.10.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.20.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.45.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (5.0.2)\n",
      "Requirement already satisfied: rich in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (14.0.0)\n",
      "Requirement already satisfied: namex in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.0.9)\n",
      "Requirement already satisfied: optree in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from markdown-it-py>=1.0->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.10.0->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.0.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.14.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.24.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (310)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\homework\\ds223\\7-transformers-zhangzwaa\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "# plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results/part_1', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7484971",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load healthcare dataset\n",
    "# This is a placeholder - replace with your actual dataset loading code\n",
    "# Example:\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# data = load_breast_cancer()\n",
    "# X, y = data.data, data.target\n",
    "\n",
    "# For demonstration, we'll use a synthetic dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, \n",
    "                          n_redundant=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092c97b",
   "metadata": {},
   "source": [
    "## 2. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple model architectures to compare\n",
    "\n",
    "def create_model_1(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Simple neural network with 2 hidden layers\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_model_2(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Deeper neural network with 4 hidden layers\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_model_3(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Wide neural network with residual connections\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(input_shape,))\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Residual block 1\n",
    "    block_1 = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    block_1 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "    block_1 = tf.keras.layers.Dropout(0.3)(block_1)\n",
    "    block_1 = tf.keras.layers.Dense(256, activation='relu')(block_1)\n",
    "    block_1 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "    block_1 = tf.keras.layers.Dropout(0.3)(block_1)\n",
    "    x = tf.keras.layers.add([x, block_1])\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instances\n",
    "model_1 = create_model_1(X_train.shape[1], len(np.unique(y)))\n",
    "model_2 = create_model_2(X_train.shape[1], len(np.unique(y)))\n",
    "model_3 = create_model_3(X_train.shape[1], len(np.unique(y)))\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Model 1 Summary:\")\n",
    "model_1.summary()\n",
    "print(\"\\nModel 2 Summary:\")\n",
    "model_2.summary()\n",
    "print(\"\\nModel 3 Summary:\")\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54f6f7",
   "metadata": {},
   "source": [
    "## 3. Cross-Validation and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77708c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate models using cross-validation\n",
    "def evaluate_model_cv(model_fn, X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Create and train model\n",
    "        model = model_fn(X.shape[1], len(np.unique(y)))\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold+1}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Evaluate models using cross-validation\n",
    "print(\"Evaluating Model 1...\")\n",
    "model_1_scores = evaluate_model_cv(create_model_1, X_train_scaled, y_train)\n",
    "print(f\"Model 1 Mean Accuracy: {np.mean(model_1_scores):.4f}, Std: {np.std(model_1_scores):.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating Model 2...\")\n",
    "model_2_scores = evaluate_model_cv(create_model_2, X_train_scaled, y_train)\n",
    "print(f\"Model 2 Mean Accuracy: {np.mean(model_2_scores):.4f}, Std: {np.std(model_2_scores):.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating Model 3...\")\n",
    "model_3_scores = evaluate_model_cv(create_model_3, X_train_scaled, y_train)\n",
    "print(f\"Model 3 Mean Accuracy: {np.mean(model_3_scores):.4f}, Std: {np.std(model_3_scores):.4f}\")\n",
    "\n",
    "# Compare model performance\n",
    "model_names = ['Simple NN', 'Deep NN', 'Residual NN']\n",
    "mean_scores = [np.mean(model_1_scores), np.mean(model_2_scores), np.mean(model_3_scores)]\n",
    "std_scores = [np.std(model_1_scores), np.std(model_2_scores), np.std(model_3_scores)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, mean_scores, yerr=std_scores, capsize=10)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.title('Model Comparison: Cross-Validation Performance')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Select the best model based on cross-validation\n",
    "best_model_idx = np.argmax(mean_scores)\n",
    "best_model_name = model_names[best_model_idx]\n",
    "print(f\"Best model based on cross-validation: {best_model_name}\")\n",
    "\n",
    "# Create and train the best model on the full training set\n",
    "if best_model_idx == 0:\n",
    "    best_model_fn = create_model_1\n",
    "elif best_model_idx == 1:\n",
    "    best_model_fn = create_model_2\n",
    "else:\n",
    "    best_model_fn = create_model_3\n",
    "\n",
    "best_model = best_model_fn(X_train.shape[1], len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107458f",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bca780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for the best model\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'models/best_model.keras',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate best model on test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, predicted_labels)\n",
    "recall = recall_score(y_test, predicted_labels)\n",
    "f1 = f1_score(y_test, predicted_labels)\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'model': best_model_name,\n",
    "    'accuracy': float(test_accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('results/part_1/model_comparison.txt', 'w') as f:\n",
    "    f.write(f\"best_model: {metrics['model']}\\n\")\n",
    "    f.write(f\"accuracy: {metrics['accuracy']}\\n\")\n",
    "    f.write(f\"precision: {metrics['precision']}\\n\")\n",
    "    f.write(f\"recall: {metrics['recall']}\\n\")\n",
    "    f.write(f\"f1_score: {metrics['f1_score']}\\n\")\n",
    "    f.write(f\"confusion_matrix: {metrics['confusion_matrix']}\\n\")\n",
    "    \n",
    "    # Also save cross-validation results\n",
    "    f.write(\"\\n--- Cross-Validation Results ---\\n\")\n",
    "    f.write(f\"model_1_mean_accuracy: {np.mean(model_1_scores)}\\n\")\n",
    "    f.write(f\"model_1_std_accuracy: {np.std(model_1_scores)}\\n\")\n",
    "    f.write(f\"model_2_mean_accuracy: {np.mean(model_2_scores)}\\n\")\n",
    "    f.write(f\"model_2_std_accuracy: {np.std(model_2_scores)}\\n\")\n",
    "    f.write(f\"model_3_mean_accuracy: {np.mean(model_3_scores)}\\n\")\n",
    "    f.write(f\"model_3_std_accuracy: {np.std(model_3_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665569e",
   "metadata": {},
   "source": [
    "## 5. Model Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model complexity vs. performance\n",
    "def count_parameters(model):\n",
    "    return np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_variables])\n",
    "\n",
    "model_1 = create_model_1(X_train.shape[1], len(np.unique(y)))\n",
    "model_2 = create_model_2(X_train.shape[1], len(np.unique(y)))\n",
    "model_3 = create_model_3(X_train.shape[1], len(np.unique(y)))\n",
    "\n",
    "param_counts = [count_parameters(model_1), count_parameters(model_2), count_parameters(model_3)]\n",
    "\n",
    "# Plot model complexity vs. performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(param_counts, mean_scores, s=100)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(param_counts, mean_scores)):\n",
    "    plt.annotate(model_names[i], (x, y), xytext=(10, 5), textcoords='offset points')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Parameters (log scale)')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.title('Model Complexity vs. Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Save complexity analysis\n",
    "with open('results/part_1/model_comparison.txt', 'a') as f:\n",
    "    f.write(\"\\n--- Model Complexity Analysis ---\\n\")\n",
    "    for i, name in enumerate(model_names):\n",
    "        f.write(f\"{name}_parameters: {param_counts[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a67435",
   "metadata": {},
   "source": [
    "## Progress Checkpoints\n",
    "\n",
    "1. **Data Loading**:\n",
    "   - [ ] Successfully load healthcare dataset\n",
    "   - [ ] Verify data shapes and ranges\n",
    "   - [ ] Split data into train/validation/test sets\n",
    "\n",
    "2. **Model Definition**:\n",
    "   - [ ] Define at least 3 different model architectures\n",
    "   - [ ] Verify architecture differences\n",
    "   - [ ] Ensure models are properly compiled\n",
    "\n",
    "3. **Cross-Validation**:\n",
    "   - [ ] Implement k-fold cross-validation\n",
    "   - [ ] Evaluate all models using cross-validation\n",
    "   - [ ] Compare model performance\n",
    "\n",
    "4. **Best Model Training**:\n",
    "   - [ ] Train best model with appropriate callbacks\n",
    "   - [ ] Monitor training progress\n",
    "   - [ ] Save best model\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - [ ] Calculate performance metrics\n",
    "   - [ ] Analyze model complexity vs. performance\n",
    "   - [ ] Save metrics in correct format\n",
    "\n",
    "## Common Issues and Solutions\n",
    "\n",
    "1. **Data Issues**:\n",
    "   - Problem: Imbalanced classes\n",
    "   - Solution: Use class weights or resampling techniques\n",
    "   - Problem: Feature scaling\n",
    "   - Solution: Apply standardization or normalization\n",
    "\n",
    "2. **Model Selection Issues**:\n",
    "   - Problem: Overfitting in complex models\n",
    "   - Solution: Add regularization, dropout, or early stopping\n",
    "   - Problem: Underfitting in simple models\n",
    "   - Solution: Increase model capacity or feature engineering\n",
    "\n",
    "3. **Cross-Validation Issues**:\n",
    "   - Problem: High variance in CV scores\n",
    "   - Solution: Increase number of folds or use stratified sampling\n",
    "   - Problem: Slow CV process\n",
    "   - Solution: Reduce epochs for CV or use a subset of data\n",
    "\n",
    "4. **Evaluation Issues**:\n",
    "   - Problem: Metrics format incorrect\n",
    "   - Solution: Follow the exact format specified\n",
    "   - Problem: Performance below expectations\n",
    "   - Solution: Try different architectures or hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
